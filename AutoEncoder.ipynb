{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch \n",
    "import numpy as np\n",
    "\n",
    "# Data preprocessing \n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/creditcard.csv')\n",
    "# print(df.info())\n",
    "# print(df.isna().sum())\n",
    "# print(df.describe().T)\n",
    "# df.corr()['Class'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, 1:-1].values\n",
    "y = df['Class'].values\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "#Changer le dataset pour l'adapter au problème de détection de fraude avec auto encoder \n",
    "X_fraud = X[y == 1]\n",
    "X_non_fraud = X[y == 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbMAAAHBCAYAAADjB1VNAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAyCUlEQVR4nO3df1yV9f3/8ecJ5YgEJxThcJSptWQaTgtK0RaaijrRrPXRYlKU49Mn/DECPjXalj8qUOePPh9dtrbKMovaDGvTGExLxwR/MFlS5uq2TPgIYoUH9WaAeH3/6Mb13RHUMA3e9bjfbud261zX61znuo4eHl0XB3RYlmUJAACDXdbROwAAwFdFzAAAxiNmAADjETMAgPGIGQDAeMQMAGA8YgYAMB4xAwAYj5gBAIxHzNDprVmzRg6HQ926ddPHH3/cav2oUaMUHR3dAXsmvf3223I4HPrDH/7QIc/fXgcOHNCkSZPUo0cPORwOpaend/QuXXQOh0Pz58/v6N3A16xLR+8A8GU1NDToF7/4hdauXdvRu2KsBx54QDt27NCzzz4rt9utiIiIjt4l4KLgzAzGmDBhgl566SX94x//6Ohd+dqdPHlSF+PXqFZUVOiGG27Q1KlTNXz4cPXt2/ci7B3Q8YgZjPHggw+qZ8+eeuihh845d+DAATkcDq1Zs6bVujMvQc2fP18Oh0PvvPOO/uM//kMul0s9evRQRkaGTp06pf3792vChAkKCgpSv379tGTJkjaf8/PPP1dGRobcbrcCAgIUHx+vPXv2tJrbvXu3pkyZoh49eqhbt2669tpr9eqrr/rMtFxWLSws1L333qtevXqpe/fuamhoOOsxHzx4UDNmzFBYWJicTqcGDhyoZcuW6fTp05L+/+XQDz/8UG+++aYcDoccDocOHDhw1m3+/ve/17Bhw+RyudS9e3ddeeWVuvfee32OOTMzU0OHDrVft7i4OL3++uttvu6zZ8/Wc889p6ioKAUEBCg2NlalpaWyLEu/+tWv1L9/f11++eW6+eab9eGHH/o8vuVS8l//+lcNHz5cAQEB6t27t375y1+qubn5rMfQoqamRvfdd5/69Okjf39/9e/fXwsWLNCpU6d85lavXq0hQ4bo8ssvV1BQkL73ve/p4YcfPu/20fGIGYwRFBSkX/ziF/rzn/+sLVu2XNRtT5s2TUOGDNH69euVmpqqFStW6IEHHtDUqVM1adIk5efn6+abb9ZDDz2k1157rdXjH374Yf3rX//S7373O/3ud7/ToUOHNGrUKP3rX/+yZ9566y2NHDlSR48e1VNPPaXXX39dQ4cO1fTp09sM77333quuXbtq7dq1+sMf/qCuXbu2ue9HjhzRiBEjVFhYqEcffVRvvPGGxo4dq6ysLM2ePVuSdN1116mkpERut1sjR45USUmJSkpKznqZsaSkRNOnT9eVV16pvLw8bdy4UY888ojPF/+GhgZ99tlnysrK0oYNG/Tyyy/rxhtv1G233aYXXnih1Tb/9Kc/6Xe/+50WLVqkl19+WceOHdOkSZOUmZmpv/3tb1q1apWefvppvffee/rRj37U6ky0pqZGd9xxh3784x/r9ddf1+23367HHntMP/3pT9s8hn9/3A033KA///nPeuSRR/Tmm29q5syZys3NVWpqqj2Xl5entLQ0xcfHKz8/Xxs2bNADDzygEydOnHP76CQsoJN77rnnLEnWrl27rIaGBuvKK6+0YmNjrdOnT1uWZVnx8fHWNddcY89/9NFHliTrueeea7UtSda8efPs+/PmzbMkWcuWLfOZGzp0qCXJeu211+xlTU1NVq9evazbbrvNXvbWW29ZkqzrrrvO3h/LsqwDBw5YXbt2tX7yk5/Yy773ve9Z1157rdXU1OTzXImJiVZERITV3Nzsc7x33XXXl3p9fvazn1mSrB07dvgsv//++y2Hw2Ht37/fXta3b19r0qRJ593m0qVLLUnW0aNHv9Q+WJZlnTp1ympqarJmzpxpXXvttT7rJFlut9s6fvy4vWzDhg2WJGvo0KE+r90TTzxhSbLeeecde1l8fLwlyXr99dd9tpuammpddtll1scff+zzXP/+Z3zfffdZl19+uc/Mvx/ju+++a1mWZc2ePdu64oorvvTxonPhzAxG8ff312OPPabdu3e3ujz3VSQmJvrcHzhwoBwOhyZOnGgv69Kli7773e+2+YnKpKQkORwO+37fvn01YsQIvfXWW5KkDz/8UO+//75+/OMfS5JOnTpl3374wx+qurpa+/fv99nmj370oy+171u2bNGgQYN0ww03+CxPSUmRZVkXdBZ7/fXXS/rijPXVV1/V//3f/7U59/vf/14jR47U5Zdfri5duqhr16565plntG/fvlazo0ePVmBgoH1/4MCBkqSJEyf6vHYty898nYOCgjRlyhSfZUlJSTp9+rS2bdt21mP505/+pNGjR8vj8fi87i1/tlu3bpUk3XDDDTp69KjuvPNOvf766/rkk0/Ouk10PsQMxrnjjjt03XXX6ec//7mampouyjZ79Ojhc9/f31/du3dXt27dWi3//PPPWz3e7Xa3uezTTz+VJB0+fFiSlJWVpa5du/rc0tLSJKnVF88v+0nDTz/9tM1Zj8djr2+vm266SRs2bNCpU6d01113qU+fPoqOjtbLL79sz7z22muaNm2aevfurRdffFElJSXatWuX7r333jZfo7Ze43MtP3Mb4eHhrbbZ8rqf6xgPHz6sP/7xj61e92uuuUbS/3/dk5OT9eyzz+rjjz/Wj370I4WFhWnYsGEqKio667bRefDRfBjH4XBo8eLFGjdunJ5++ulW61sCdOYHJi7ki/qXVVNT0+aynj17SpJCQ0MlSdnZ2brtttva3EZUVJTP/X8/WzmXnj17qrq6utXyQ4cO+Tx3e91yyy265ZZb1NDQoNLSUuXm5iopKUn9+vVTXFycXnzxRfXv31+vvPKKz76e64MqX0XL/xD8u5bXveV1bktoaKi+//3v6/HHH29zfUv0Jemee+7RPffcoxMnTmjbtm2aN2+eEhMT9c9//pNPfnZyxAxGGjt2rMaNG6eFCxcqMjLSZ114eLi6deumd955x2d5W5+yu1hefvllZWRk2F/UP/74Y23fvl133XWXpC9CdfXVV+sf//iHcnJyLupzjxkzRrm5ufr73/+u6667zl7+wgsvyOFwaPTo0V9p+06nU/Hx8briiiv05z//WXv27FFcXJwcDof8/f19QlZTU3PJXudjx47pjTfe8LnU+NJLL+myyy7TTTfddNbHJSYmatOmTbrqqqsUEhLypZ4rMDBQEydOVGNjo6ZOnap3332XmHVyxAzGWrx4sWJiYlRbW2tfMpK+OKOZMWOGnn32WV111VUaMmSIdu7cqZdeeumS7Uttba1uvfVWpaamyuv1at68eerWrZuys7Ptmd/85jeaOHGixo8fr5SUFPXu3VufffaZ9u3bp7///e/6/e9/f0HP/cADD+iFF17QpEmTtHDhQvXt21cbN27Uk08+qfvvv18DBgxo9zYfeeQRVVVVacyYMerTp4+OHj2q//mf/1HXrl0VHx8v6YtIvPbaa0pLS9Ptt9+uyspKPfroo4qIiNAHH3xwQcdyLj179tT999+vgwcPasCAAdq0aZN++9vf6v7779d3vvOdsz5u4cKFKioq0ogRIzR37lxFRUXp888/14EDB7Rp0yY99dRT6tOnj1JTUxUQEKCRI0cqIiJCNTU1ys3Nlcvlsr+HiM6LmMFY1157re688842I7Vs2TJJ0pIlS3T8+HHdfPPN+tOf/qR+/fpdkn3JycnRrl27dM8996i+vl433HCD8vLydNVVV9kzo0eP1s6dO/X4448rPT1ddXV16tmzpwYNGqRp06Zd8HP36tVL27dvV3Z2trKzs1VfX68rr7xSS5YsUUZGxgVtc9iwYdq9e7ceeughHTlyRFdccYViY2O1ZcsW+38c7rnnHtXW1uqpp57Ss88+qyuvvFI/+9nPVFVVpQULFlzw8ZyN2+3Wr3/9a2VlZWnv3r3q0aOHHn744fM+V0REhHbv3q1HH31Uv/rVr1RVVaWgoCD1799fEyZMsM/WfvCDH2jNmjV69dVXVVdXp9DQUN1444164YUX1KtXr4t+PLi4HJZ1EX6tAABcQqNGjdInn3yiioqKjt4VdFJ8mhEAYDxiBgAwHpcZAQDG48wMAGA8YgYAMB4xAwAYj58zO4/Tp0/r0KFDCgoK+tK/XggA8NVZlqVjx47J4/HossvOfe5FzM7j0KFDrX5dEgDg61NZWak+ffqcc4aYnUdQUJCkL17M4ODgDt4bAPj2qK+vV2RkpP11+FyI2Xm0XFoMDg4mZgDQAb7Mt3j4AAgAwHjEDABgPGIGADAeMQMAGI+YAQCMR8wAAMYjZgAA4xEzAIDxiBkAwHjEDABgPGIGADAeMQMAGI+YAQCMR8wAAMYjZgAA4xEzAIDx+Mc5AXwpjgXn/wcSgTNZ86yv5Xk4MwMAGI+YAQCMR8wAAMYjZgAA4xEzAIDxiBkAwHjEDABgPGIGADAeMQMAGI+YAQCMR8wAAMYjZgAA4xEzAIDxiBkAwHjEDABgPGIGADAeMQMAGI+YAQCMR8wAAMYjZgAA4xEzAIDxiBkAwHjEDABgPGIGADAeMQMAGI+YAQCMR8wAAMYjZgAA4xEzAIDxiBkAwHjEDABgPGIGADAeMQMAGI+YAQCMR8wAAMYjZgAA4xEzAIDxiBkAwHjtillubq6uv/56BQUFKSwsTFOnTtX+/ft9ZlJSUuRwOHxuw4cP95lpaGjQnDlzFBoaqsDAQE2ZMkVVVVU+M3V1dUpOTpbL5ZLL5VJycrKOHj3qM3Pw4EFNnjxZgYGBCg0N1dy5c9XY2Ogzs3fvXsXHxysgIEC9e/fWwoULZVlWew4bANDJtStmW7du1axZs1RaWqqioiKdOnVKCQkJOnHihM/chAkTVF1dbd82bdrksz49PV35+fnKy8tTcXGxjh8/rsTERDU3N9szSUlJKi8vV0FBgQoKClReXq7k5GR7fXNzsyZNmqQTJ06ouLhYeXl5Wr9+vTIzM+2Z+vp6jRs3Th6PR7t27dLKlSu1dOlSLV++vF0vEgCgc3NYX+E05ciRIwoLC9PWrVt10003SfrizOzo0aPasGFDm4/xer3q1auX1q5dq+nTp0uSDh06pMjISG3atEnjx4/Xvn37NGjQIJWWlmrYsGGSpNLSUsXFxen9999XVFSU3nzzTSUmJqqyslIej0eSlJeXp5SUFNXW1io4OFirV69Wdna2Dh8+LKfTKUlatGiRVq5cqaqqKjkcjvMeY319vVwul7xer4KDgy/0pQKM51hw/vcLcCZr3oVfCWvP19+v9D0zr9crSerRo4fP8rffflthYWEaMGCAUlNTVVtba68rKytTU1OTEhIS7GUej0fR0dHavn27JKmkpEQul8sOmSQNHz5cLpfLZyY6OtoOmSSNHz9eDQ0NKisrs2fi4+PtkLXMHDp0SAcOHPgqhw4A6EQuOGaWZSkjI0M33nijoqOj7eUTJ07UunXrtGXLFi1btky7du3SzTffrIaGBklSTU2N/P39FRIS4rO98PBw1dTU2DNhYWGtnjMsLMxnJjw83Gd9SEiI/P39zznTcr9l5kwNDQ2qr6/3uQEAOrcuF/rA2bNn65133lFxcbHP8pZLh5IUHR2t2NhY9e3bVxs3btRtt9121u1ZluVz2a+tS4AXY6blqurZLjHm5uZqwYIFZ91PAEDnc0FnZnPmzNEbb7yht956S3369DnnbEREhPr27asPPvhAkuR2u9XY2Ki6ujqfudraWvusye126/Dhw622deTIEZ+ZM8+u6urq1NTUdM6ZlkueZ56xtcjOzpbX67VvlZWV5zw+AEDHa1fMLMvS7Nmz9dprr2nLli3q37//eR/z6aefqrKyUhEREZKkmJgYde3aVUVFRfZMdXW1KioqNGLECElSXFycvF6vdu7cac/s2LFDXq/XZ6aiokLV1dX2TGFhoZxOp2JiYuyZbdu2+Xxcv7CwUB6PR/369Wtzf51Op4KDg31uAIDOrV0xmzVrll588UW99NJLCgoKUk1NjWpqanTy5ElJ0vHjx5WVlaWSkhIdOHBAb7/9tiZPnqzQ0FDdeuutkiSXy6WZM2cqMzNTmzdv1p49ezRjxgwNHjxYY8eOlSQNHDhQEyZMUGpqqkpLS1VaWqrU1FQlJiYqKipKkpSQkKBBgwYpOTlZe/bs0ebNm5WVlaXU1FQ7QElJSXI6nUpJSVFFRYXy8/OVk5OjjIyML/VJRgCAGdoVs9WrV8vr9WrUqFGKiIiwb6+88ookyc/PT3v37tUtt9yiAQMG6O6779aAAQNUUlKioKAgezsrVqzQ1KlTNW3aNI0cOVLdu3fXH//4R/n5+dkz69at0+DBg5WQkKCEhAR9//vf19q1a+31fn5+2rhxo7p166aRI0dq2rRpmjp1qpYuXWrPuFwuFRUVqaqqSrGxsUpLS1NGRoYyMjIu+AUDAHQ+X+nnzL4N+Dkz4Av8nBkuhBE/ZwYAQGdAzAAAxiNmAADjETMAgPGIGQDAeMQMAGA8YgYAMB4xAwAYj5gBAIxHzAAAxiNmAADjETMAgPGIGQDAeMQMAGA8YgYAMB4xAwAYj5gBAIxHzAAAxiNmAADjETMAgPGIGQDAeMQMAGA8YgYAMB4xAwAYj5gBAIxHzAAAxiNmAADjETMAgPGIGQDAeMQMAGA8YgYAMB4xAwAYj5gBAIxHzAAAxiNmAADjETMAgPGIGQDAeMQMAGA8YgYAMB4xAwAYj5gBAIxHzAAAxiNmAADjETMAgPGIGQDAeMQMAGA8YgYAMB4xAwAYj5gBAIxHzAAAxiNmAADjETMAgPGIGQDAeMQMAGC8dsUsNzdX119/vYKCghQWFqapU6dq//79PjOWZWn+/PnyeDwKCAjQqFGj9O677/rMNDQ0aM6cOQoNDVVgYKCmTJmiqqoqn5m6ujolJyfL5XLJ5XIpOTlZR48e9Zk5ePCgJk+erMDAQIWGhmru3LlqbGz0mdm7d6/i4+MVEBCg3r17a+HChbIsqz2HDQDo5NoVs61bt2rWrFkqLS1VUVGRTp06pYSEBJ04ccKeWbJkiZYvX65Vq1Zp165dcrvdGjdunI4dO2bPpKenKz8/X3l5eSouLtbx48eVmJio5uZmeyYpKUnl5eUqKChQQUGBysvLlZycbK9vbm7WpEmTdOLECRUXFysvL0/r169XZmamPVNfX69x48bJ4/Fo165dWrlypZYuXarly5df0IsFAOicHNZXOE05cuSIwsLCtHXrVt10002yLEsej0fp6el66KGHJH1xFhYeHq7Fixfrvvvuk9frVa9evbR27VpNnz5dknTo0CFFRkZq06ZNGj9+vPbt26dBgwaptLRUw4YNkySVlpYqLi5O77//vqKiovTmm28qMTFRlZWV8ng8kqS8vDylpKSotrZWwcHBWr16tbKzs3X48GE5nU5J0qJFi7Ry5UpVVVXJ4XCc9xjr6+vlcrnk9XoVHBx8oS8VYDzHgvO/X4AzWfMu/EpYe77+fqXvmXm9XklSjx49JEkfffSRampqlJCQYM84nU7Fx8dr+/btkqSysjI1NTX5zHg8HkVHR9szJSUlcrlcdsgkafjw4XK5XD4z0dHRdsgkafz48WpoaFBZWZk9Ex8fb4esZebQoUM6cOBAm8fU0NCg+vp6nxsAoHO74JhZlqWMjAzdeOONio6OliTV1NRIksLDw31mw8PD7XU1NTXy9/dXSEjIOWfCwsJaPWdYWJjPzJnPExISIn9//3POtNxvmTlTbm6u/X06l8ulyMjI87wSAICOdsExmz17tt555x29/PLLrdadefnOsqzzXtI7c6at+Ysx03JV9Wz7k52dLa/Xa98qKyvPud8AgI53QTGbM2eO3njjDb311lvq06ePvdztdktqfdZTW1trnxG53W41Njaqrq7unDOHDx9u9bxHjhzxmTnzeerq6tTU1HTOmdraWkmtzx5bOJ1OBQcH+9wAAJ1bu2JmWZZmz56t1157TVu2bFH//v191vfv319ut1tFRUX2ssbGRm3dulUjRoyQJMXExKhr164+M9XV1aqoqLBn4uLi5PV6tXPnTntmx44d8nq9PjMVFRWqrq62ZwoLC+V0OhUTE2PPbNu2zefj+oWFhfJ4POrXr197Dh0A0Im1K2azZs3Siy++qJdeeklBQUGqqalRTU2NTp48KemLS3fp6enKyclRfn6+KioqlJKSou7duyspKUmS5HK5NHPmTGVmZmrz5s3as2ePZsyYocGDB2vs2LGSpIEDB2rChAlKTU1VaWmpSktLlZqaqsTEREVFRUmSEhISNGjQICUnJ2vPnj3avHmzsrKylJqaap9NJSUlyel0KiUlRRUVFcrPz1dOTo4yMjK+1CcZAQBm6NKe4dWrV0uSRo0a5bP8ueeeU0pKiiTpwQcf1MmTJ5WWlqa6ujoNGzZMhYWFCgoKsudXrFihLl26aNq0aTp58qTGjBmjNWvWyM/Pz55Zt26d5s6da3/qccqUKVq1apW93s/PTxs3blRaWppGjhypgIAAJSUlaenSpfaMy+VSUVGRZs2apdjYWIWEhCgjI0MZGRntOWwAQCf3lX7O7NuAnzMDvsDPmeFCGPFzZgAAdAbEDABgPGIGADAeMQMAGI+YAQCMR8wAAMYjZgAA4xEzAIDxiBkAwHjEDABgPGIGADAeMQMAGI+YAQCMR8wAAMYjZgAA4xEzAIDxiBkAwHjEDABgPGIGADAeMQMAGI+YAQCMR8wAAMYjZgAA4xEzAIDxiBkAwHjEDABgPGIGADAeMQMAGI+YAQCMR8wAAMYjZgAA4xEzAIDxiBkAwHjEDABgPGIGADAeMQMAGI+YAQCMR8wAAMYjZgAA4xEzAIDxiBkAwHjEDABgPGIGADAeMQMAGI+YAQCMR8wAAMYjZgAA4xEzAIDxiBkAwHjEDABgPGIGADAeMQMAGI+YAQCM1+6Ybdu2TZMnT5bH45HD4dCGDRt81qekpMjhcPjchg8f7jPT0NCgOXPmKDQ0VIGBgZoyZYqqqqp8Zurq6pScnCyXyyWXy6Xk5GQdPXrUZ+bgwYOaPHmyAgMDFRoaqrlz56qxsdFnZu/evYqPj1dAQIB69+6thQsXyrKs9h42AKATa3fMTpw4oSFDhmjVqlVnnZkwYYKqq6vt26ZNm3zWp6enKz8/X3l5eSouLtbx48eVmJio5uZmeyYpKUnl5eUqKChQQUGBysvLlZycbK9vbm7WpEmTdOLECRUXFysvL0/r169XZmamPVNfX69x48bJ4/Fo165dWrlypZYuXarly5e397ABAJ1Yl/Y+YOLEiZo4ceI5Z5xOp9xud5vrvF6vnnnmGa1du1Zjx46VJL344ouKjIzUX/7yF40fP1779u1TQUGBSktLNWzYMEnSb3/7W8XFxWn//v2KiopSYWGh3nvvPVVWVsrj8UiSli1bppSUFD3++OMKDg7WunXr9Pnnn2vNmjVyOp2Kjo7WP//5Ty1fvlwZGRlyOBztPXwAQCd0Sb5n9vbbbyssLEwDBgxQamqqamtr7XVlZWVqampSQkKCvczj8Sg6Olrbt2+XJJWUlMjlctkhk6Thw4fL5XL5zERHR9shk6Tx48eroaFBZWVl9kx8fLycTqfPzKFDh3TgwIFLcegAgA5w0WM2ceJErVu3Tlu2bNGyZcu0a9cu3XzzzWpoaJAk1dTUyN/fXyEhIT6PCw8PV01NjT0TFhbWatthYWE+M+Hh4T7rQ0JC5O/vf86ZlvstM2dqaGhQfX29zw0A0Lm1+zLj+UyfPt3+7+joaMXGxqpv377auHGjbrvttrM+zrIsn8t+bV0CvBgzLR/+ONslxtzcXC1YsOCs+wkA6Hwu+UfzIyIi1LdvX33wwQeSJLfbrcbGRtXV1fnM1dbW2mdNbrdbhw8fbrWtI0eO+MyceXZVV1enpqamc860XPI884ytRXZ2trxer32rrKxs7yEDAL5mlzxmn376qSorKxURESFJiomJUdeuXVVUVGTPVFdXq6KiQiNGjJAkxcXFyev1aufOnfbMjh075PV6fWYqKipUXV1tzxQWFsrpdComJsae2bZtm8/H9QsLC+XxeNSvX78299fpdCo4ONjnBgDo3Nods+PHj6u8vFzl5eWSpI8++kjl5eU6ePCgjh8/rqysLJWUlOjAgQN6++23NXnyZIWGhurWW2+VJLlcLs2cOVOZmZnavHmz9uzZoxkzZmjw4MH2pxsHDhyoCRMmKDU1VaWlpSotLVVqaqoSExMVFRUlSUpISNCgQYOUnJysPXv2aPPmzcrKylJqaqodoKSkJDmdTqWkpKiiokL5+fnKycnhk4wA8A3T7u+Z7d69W6NHj7bvZ2RkSJLuvvturV69Wnv37tULL7ygo0ePKiIiQqNHj9Yrr7yioKAg+zErVqxQly5dNG3aNJ08eVJjxozRmjVr5OfnZ8+sW7dOc+fOtT/1OGXKFJ+fbfPz89PGjRuVlpamkSNHKiAgQElJSVq6dKk943K5VFRUpFmzZik2NlYhISHKyMiw9xkA8M3gsPh1GOdUX18vl8slr9fLJUd8qzkWcDUD7WfNu/DEtOfrL7+bEQBgPGIGADAeMQMAGI+YAQCMR8wAAMYjZgAA4xEzAIDxiBkAwHjEDABgPGIGADAeMQMAGI+YAQCMR8wAAMYjZgAA4xEzAIDxiBkAwHjEDABgPGIGADAeMQMAGI+YAQCMR8wAAMYjZgAA4xEzAIDxiBkAwHjEDABgPGIGADAeMQMAGI+YAQCMR8wAAMYjZgAA4xEzAIDxiBkAwHjEDABgPGIGADAeMQMAGI+YAQCMR8wAAMYjZgAA4xEzAIDxiBkAwHjEDABgPGIGADAeMQMAGI+YAQCMR8wAAMYjZgAA4xEzAIDxiBkAwHjEDABgPGIGADAeMQMAGI+YAQCMR8wAAMYjZgAA47U7Ztu2bdPkyZPl8XjkcDi0YcMGn/WWZWn+/PnyeDwKCAjQqFGj9O677/rMNDQ0aM6cOQoNDVVgYKCmTJmiqqoqn5m6ujolJyfL5XLJ5XIpOTlZR48e9Zk5ePCgJk+erMDAQIWGhmru3LlqbGz0mdm7d6/i4+MVEBCg3r17a+HChbIsq72HDQDoxNodsxMnTmjIkCFatWpVm+uXLFmi5cuXa9WqVdq1a5fcbrfGjRunY8eO2TPp6enKz89XXl6eiouLdfz4cSUmJqq5udmeSUpKUnl5uQoKClRQUKDy8nIlJyfb65ubmzVp0iSdOHFCxcXFysvL0/r165WZmWnP1NfXa9y4cfJ4PNq1a5dWrlyppUuXavny5e09bABAJ+awvsJpisPhUH5+vqZOnSrpi7Myj8ej9PR0PfTQQ5K+OAsLDw/X4sWLdd9998nr9apXr15au3atpk+fLkk6dOiQIiMjtWnTJo0fP1779u3ToEGDVFpaqmHDhkmSSktLFRcXp/fff19RUVF68803lZiYqMrKSnk8HklSXl6eUlJSVFtbq+DgYK1evVrZ2dk6fPiwnE6nJGnRokVauXKlqqqq5HA4znuM9fX1crlc8nq9Cg4OvtCXCjCeY8H53y/Amax5F34lrD1ffy/q98w++ugj1dTUKCEhwV7mdDoVHx+v7du3S5LKysrU1NTkM+PxeBQdHW3PlJSUyOVy2SGTpOHDh8vlcvnMREdH2yGTpPHjx6uhoUFlZWX2THx8vB2ylplDhw7pwIEDbR5DQ0OD6uvrfW4AgM7tosaspqZGkhQeHu6zPDw83F5XU1Mjf39/hYSEnHMmLCys1fbDwsJ8Zs58npCQEPn7+59zpuV+y8yZcnNz7e/TuVwuRUZGnv/AAQAd6pJ8mvHMy3eWZZ33kt6ZM23NX4yZlquqZ9uf7Oxseb1e+1ZZWXnO/QYAdLyLGjO32y2p9VlPbW2tfUbkdrvV2Niourq6c84cPny41faPHDniM3Pm89TV1ampqemcM7W1tZJanz22cDqdCg4O9rkBADq3ixqz/v37y+12q6ioyF7W2NiorVu3asSIEZKkmJgYde3a1WemurpaFRUV9kxcXJy8Xq927txpz+zYsUNer9dnpqKiQtXV1fZMYWGhnE6nYmJi7Jlt27b5fFy/sLBQHo9H/fr1u5iHDgDoQO2O2fHjx1VeXq7y8nJJX3zoo7y8XAcPHpTD4VB6erpycnKUn5+viooKpaSkqHv37kpKSpIkuVwuzZw5U5mZmdq8ebP27NmjGTNmaPDgwRo7dqwkaeDAgZowYYJSU1NVWlqq0tJSpaamKjExUVFRUZKkhIQEDRo0SMnJydqzZ482b96srKwspaam2mdTSUlJcjqdSklJUUVFhfLz85WTk6OMjIwv9UlGAIAZurT3Abt379bo0aPt+xkZGZKku+++W2vWrNGDDz6okydPKi0tTXV1dRo2bJgKCwsVFBRkP2bFihXq0qWLpk2bppMnT2rMmDFas2aN/Pz87Jl169Zp7ty59qcep0yZ4vOzbX5+ftq4caPS0tI0cuRIBQQEKCkpSUuXLrVnXC6XioqKNGvWLMXGxiokJEQZGRn2PgMAvhm+0s+ZfRvwc2bAF/g5M1wII3/ODACAjkDMAADGI2YAAOMRMwCA8YgZAMB4xAwAYDxiBgAwHjEDABiPmAEAjEfMAADGI2YAAOMRMwCA8YgZAMB4xAwAYDxiBgAwHjEDABiPmAEAjEfMAADGI2YAAOMRMwCA8YgZAMB4xAwAYDxiBgAwHjEDABiPmAEAjEfMAADGI2YAAOMRMwCA8YgZAMB4xAwAYDxiBgAwHjEDABiPmAEAjEfMAADGI2YAAOMRMwCA8YgZAMB4xAwAYDxiBgAwHjEDABiPmAEAjEfMAADGI2YAAOMRMwCA8YgZAMB4xAwAYDxiBgAwHjEDABiPmAEAjEfMAADGI2YAAOMRMwCA8YgZAMB4Fz1m8+fPl8Ph8Lm53W57vWVZmj9/vjwejwICAjRq1Ci9++67PttoaGjQnDlzFBoaqsDAQE2ZMkVVVVU+M3V1dUpOTpbL5ZLL5VJycrKOHj3qM3Pw4EFNnjxZgYGBCg0N1dy5c9XY2HixDxkA0MEuyZnZNddco+rqavu2d+9ee92SJUu0fPlyrVq1Srt27ZLb7da4ceN07NgxeyY9PV35+fnKy8tTcXGxjh8/rsTERDU3N9szSUlJKi8vV0FBgQoKClReXq7k5GR7fXNzsyZNmqQTJ06ouLhYeXl5Wr9+vTIzMy/FIQMAOlCXS7LRLl18zsZaWJalJ554Qj//+c912223SZKef/55hYeH66WXXtJ9990nr9erZ555RmvXrtXYsWMlSS+++KIiIyP1l7/8RePHj9e+fftUUFCg0tJSDRs2TJL029/+VnFxcdq/f7+ioqJUWFio9957T5WVlfJ4PJKkZcuWKSUlRY8//riCg4MvxaEDADrAJTkz++CDD+TxeNS/f3/dcccd+te//iVJ+uijj1RTU6OEhAR71ul0Kj4+Xtu3b5cklZWVqampyWfG4/EoOjranikpKZHL5bJDJknDhw+Xy+XymYmOjrZDJknjx49XQ0ODysrKLsVhAwA6yEU/Mxs2bJheeOEFDRgwQIcPH9Zjjz2mESNG6N1331VNTY0kKTw83Ocx4eHh+vjjjyVJNTU18vf3V0hISKuZlsfX1NQoLCys1XOHhYX5zJz5PCEhIfL397dn2tLQ0KCGhgb7fn19/Zc9dABAB7noMZs4caL934MHD1ZcXJyuuuoqPf/88xo+fLgkyeFw+DzGsqxWy8505kxb8xcyc6bc3FwtWLDgnPsCAOhcLvlH8wMDAzV48GB98MEH9vfRzjwzqq2ttc+i3G63GhsbVVdXd86Zw4cPt3quI0eO+Myc+Tx1dXVqampqdcb277Kzs+X1eu1bZWVlO48YAPB1u+Qxa2ho0L59+xQREaH+/fvL7XarqKjIXt/Y2KitW7dqxIgRkqSYmBh17drVZ6a6uloVFRX2TFxcnLxer3bu3GnP7NixQ16v12emoqJC1dXV9kxhYaGcTqdiYmLOur9Op1PBwcE+NwBA53bRLzNmZWVp8uTJ+s53vqPa2lo99thjqq+v19133y2Hw6H09HTl5OTo6quv1tVXX62cnBx1795dSUlJkiSXy6WZM2cqMzNTPXv2VI8ePZSVlaXBgwfbn24cOHCgJkyYoNTUVP3mN7+RJP3nf/6nEhMTFRUVJUlKSEjQoEGDlJycrF/96lf67LPPlJWVpdTUVAIFAN8wFz1mVVVVuvPOO/XJJ5+oV69eGj58uEpLS9W3b19J0oMPPqiTJ08qLS1NdXV1GjZsmAoLCxUUFGRvY8WKFerSpYumTZumkydPasyYMVqzZo38/PzsmXXr1mnu3Ln2px6nTJmiVatW2ev9/Py0ceNGpaWlaeTIkQoICFBSUpKWLl16sQ8ZANDBHJZlWR29E51ZfX29XC6XvF4vZ3T4VnMsOPeHtIC2WPMuPDHt+frL72YEABiPmAEAjEfMAADGI2YAAOMRMwCA8YgZAMB4xAwAYDxiBgAwHjEDABiPmAEAjEfMAADGI2YAAOMRMwCA8YgZAMB4xAwAYDxiBgAwHjEDABiPmAEAjEfMAADGI2YAAOMRMwCA8YgZAMB4xAwAYDxiBgAwHjEDABiPmAEAjEfMAADGI2YAAOMRMwCA8YgZAMB4xAwAYDxiBgAwHjEDABiPmAEAjEfMAADGI2YAAOMRMwCA8YgZAMB4xAwAYDxiBgAwHjEDABiPmAEAjEfMAADGI2YAAOMRMwCA8YgZAMB4xAwAYDxiBgAwHjEDABiPmAEAjEfMAADGI2YAAOMRMwCA8YgZAMB434qYPfnkk+rfv7+6deummJgY/fWvf+3oXQIAXETf+Ji98sorSk9P189//nPt2bNHP/jBDzRx4kQdPHiwo3cNAHCRfONjtnz5cs2cOVM/+clPNHDgQD3xxBOKjIzU6tWrO3rXAAAXSZeO3oFLqbGxUWVlZfrZz37mszwhIUHbt29v8zENDQ1qaGiw73u9XklSfX39pdtRwASfd/QOwERf5Wtny2Mtyzrv7Dc6Zp988omam5sVHh7uszw8PFw1NTVtPiY3N1cLFixotTwyMvKS7CMAfJO5Frm+8jaOHTsml+vc2/lGx6yFw+HwuW9ZVqtlLbKzs5WRkWHfP336tD777DP17NnzrI/Bhamvr1dkZKQqKysVHBzc0bsDXBD+Hl86lmXp2LFj8ng85539RscsNDRUfn5+rc7CamtrW52ttXA6nXI6nT7Lrrjiiku1i5AUHBzMFwEYj7/Hl8b5zshafKM/AOLv76+YmBgVFRX5LC8qKtKIESM6aK8AABfbN/rMTJIyMjKUnJys2NhYxcXF6emnn9bBgwf1X//1Xx29awCAi+QbH7Pp06fr008/1cKFC1VdXa3o6Ght2rRJffv27ehd+9ZzOp2aN29eq8u6gEn4e9w5OKwv85lHAAA6sW/098wAAN8OxAwAYDxiBgAwHjGD0VJSUjR16tSO3g2gw33b3wvEDBckJSVFDoej1e3DDz/s6F3Dt0jL38NFixb5LN+wYcPX8ht7eB90HsQMF2zChAmqrq72ufXv399nprGxsYP2Dt8W3bp10+LFi1VXV9chz/9l3gcS74VLjZjhgjmdTrndbp/bmDFjNHv2bGVkZCg0NFTjxo2T9MU/xTN48GAFBgYqMjJSaWlpOn78uL2t+fPna+jQoT7bf+KJJ9SvXz/7fnNzszIyMnTFFVeoZ8+eevDBB7/Ub9PGN9vYsWPldruVm5t7zrn169frmmuukdPpVL9+/bRs2TKf9f369VNOTo7uvfdeBQUF6Tvf+Y6efvrp8z5/W+8DPz8/jRo1ivfC14iY4aJ7/vnn1aVLF/3tb3/Tb37zG0nSZZddpv/93/9VRUWFnn/+eW3ZskUPPvhgu7a7bNkyPfvss3rmmWdUXFyszz77TPn5+ZfiEGAQPz8/5eTkaOXKlaqqqmpzpqysTNOmTdMdd9yhvXv3av78+frlL3+pNWvW+MwtW7ZMsbGx2rNnj9LS0nT//ffr/fffv+B9473wNbKAC3D33Xdbfn5+VmBgoH27/fbbrfj4eGvo0KHnffyrr75q9ezZ074/b948a8iQIT4zK1assPr27Wvfj4iIsBYtWmTfb2pqsvr06WPdcsstX/VwYKi7777b/vMfPny4de+991qWZVn5+fnWv395S0pKssaNG+fz2P/+7/+2Bg0aZN/v27evNWPGDPv+6dOnrbCwMGv16tXnfP623geWZfFe+Jp943+dFS6d0aNH+/yL3YGBgbrzzjsVGxvbavatt95STk6O3nvvPdXX1+vUqVP6/PPPdeLECQUGBp73ubxer6qrqxUXF2cv69Kli2JjY7/1l1fwhcWLF+vmm29WZmZmq3X79u3TLbfc4rNs5MiReuKJJ9Tc3Cw/Pz9J0ve//317vcPhkNvtVm1t7Tmft633QQveC18fLjPiggUGBuq73/2ufYuIiLCX/7uPP/5YP/zhDxUdHa3169errKxMv/71ryVJTU1Nkr649HLmG7FlHfBl3HTTTRo/frwefvjhVuusNv4Nw7a+8Hft2tXnvsPh0OnTp8/5vGd7H7Ss+3e8Fy4dYoZLbvfu3Tp16pSWLVum4cOHa8CAATp06JDPTK9evVRTU+PzJi4vL7f/2+VyKSIiQqWlpfayU6dOqays7JLvP8yxaNEi/fGPf9T27dt9lg8aNEjFxcU+y7Zv364BAwbYZ2VfB94Llw6XGXHJXXXVVTp16pRWrlypyZMn629/+5ueeuopn5lRo0bpyJEjWrJkiW6//XYVFBTozTff9PnHDn/6059q0aJFuvrqqzVw4EAtX75cR48e/ZqPBp3Z4MGD9eMf/1grV670WZ6Zmanrr79ejz76qKZPn66SkhKtWrVKTz755Ne6f7wXLh3OzHDJDR06VMuXL9fixYsVHR2tdevWtfoY9cCBA/Xkk0/q17/+tYYMGaKdO3cqKyvLZyYzM1N33XWXUlJSFBcXp6CgIN16661f56HAAI8++miry3TXXXedXn31VeXl5Sk6OlqPPPKIFi5cqJSUlK9133gvXDr8EzAAAONxZgYAMB4xAwAYj5gBAIxHzAAAxiNmAADjETMAgPGIGQDAeMQMAGA8YgYAMB4xAwAYj5gBAIxHzAAAxvt/d5LG2Pb23hAAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0    284315\n",
       "1       492\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Visualisation len fraud and non fraud\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(['Fraud', 'Non Fraud'], [len(X_fraud), len(X_non_fraud)], color=['red', 'green'])\n",
    "plt.title('Number of samples')\n",
    "plt.show()\n",
    "df['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train_non_fraud = X_non_fraud[:int(len(X_non_fraud) * 0.9)]\n",
    "X_test_fraud = X_fraud\n",
    "X_test_non_fraud = X_non_fraud[int(len(X_non_fraud) * 0.1):]\n",
    "\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "X_test_fraud = np.array(X_test_fraud, dtype=np.float32)\n",
    "X_test_non_fraud = np.array(X_test_non_fraud, dtype=np.float32)\n",
    "\n",
    "# Concaténer les tableaux\n",
    "X_train = np.array(X_train_non_fraud, dtype=np.float32)\n",
    "y_train = np.zeros(X_train.shape[0], dtype=np.float32)\n",
    "\n",
    "X_test = np.concatenate((X_test_fraud, X_test_non_fraud), axis=0)\n",
    "y_test = np.concatenate((np.ones(X_test_fraud.shape[0]), np.zeros(X_test_non_fraud.shape[0])))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00000000e+00, -1.35980713e+00, -7.27811733e-02,  2.53634674e+00,\n",
       "        1.37815522e+00, -3.38320770e-01,  4.62387778e-01,  2.39598554e-01,\n",
       "        9.86979013e-02,  3.63786970e-01,  9.07941720e-02, -5.51599533e-01,\n",
       "       -6.17800856e-01, -9.91389847e-01, -3.11169354e-01,  1.46817697e+00,\n",
       "       -4.70400525e-01,  2.07971242e-01,  2.57905802e-02,  4.03992960e-01,\n",
       "        2.51412098e-01, -1.83067779e-02,  2.77837576e-01, -1.10473910e-01,\n",
       "        6.69280749e-02,  1.28539358e-01, -1.89114844e-01,  1.33558377e-01,\n",
       "       -2.10530535e-02,  1.49620000e+02])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CardFraudDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        #Convert data to tensor.float32\n",
    "        self.data = torch.tensor(data, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.float32)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "\n",
    "    \n",
    "train_cardFraudDataset = CardFraudDataset(X_train, y_train)\n",
    "test_cardFraudDataset = CardFraudDataset(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_cardFraudDataset, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_cardFraudDataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module): \n",
    "    def __init__(self, input_dim):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 24),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(24, 12),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(12, 6),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(6, 12),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(12, 24),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(24, input_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_fraud(loss):\n",
    "    \"\"\"Classify a transaction as fraud or not based on reconstruction loss.\"\"\"\n",
    "    threshold = 0.2  # Define a threshold for classification\n",
    "    return 0 if loss < threshold else 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 1/100,Reconstruction Loss: 766.5527,  Precision: 0.0019, Recall: 1.0000, Accuracy: 0.0019, F1 Score: 0.0038\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[136], line 30\u001b[0m\n\u001b[1;32m     28\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n\u001b[1;32m     29\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, inputs)\n\u001b[0;32m---> 30\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     32\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/cardfraud/lib/python3.9/site-packages/torch/_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    520\u001b[0m     )\n\u001b[0;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/cardfraud/lib/python3.9/site-packages/torch/autograd/__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/cardfraud/lib/python3.9/site-packages/torch/autograd/graph.py:768\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    766\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 768\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    769\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    770\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    771\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "\n",
    "# Hyperparameters\n",
    "latent_dim = 10\n",
    "input_dim = X_train.shape[1]  # Number of features\n",
    "lr = 1e-4\n",
    "epochs = 100\n",
    "\n",
    "# Define the model, loss, and optimizer\n",
    "model = AutoEncoder(input_dim=input_dim).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    for data, _ in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        inputs = data.to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, inputs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    true_labels = []\n",
    "    pred_labels = []\n",
    "    with torch.no_grad():\n",
    "        test_loss = 0.0\n",
    "        for data, labels in test_dataloader:\n",
    "            inputs = data.to(device)\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # Reconstruction loss\n",
    "            reconstruction_loss = nn.MSELoss(reduction='none')(outputs, inputs).sum(dim=1)\n",
    "            # Classify based on reconstruction loss\n",
    "            fraud_predictions = [classifier_fraud(loss.item()) for loss in reconstruction_loss]\n",
    "            true_labels.extend(labels.numpy())\n",
    "            pred_labels.extend(fraud_predictions)\n",
    "\n",
    "            # Calculate classification loss (for demonstration)\n",
    "            classification_targets = torch.tensor(fraud_predictions, device=device, dtype=torch.float32)\n",
    "            ground_truth = labels\n",
    "            loss_classification = nn.CrossEntropyLoss()(classification_targets, ground_truth)\n",
    "            test_loss += loss.item()\n",
    "        \n",
    "        # Confusion Matrix\n",
    "        print(f\" Epoch {epoch + 1}/{epochs},Reconstruction Loss: {train_loss / len(train_dataloader):.4f},  Precision: {precision_score(true_labels, pred_labels):.4f}, Recall: {recall_score(true_labels, pred_labels):.4f}, Accuracy: {accuracy_score(true_labels, pred_labels):.4f}, F1 Score: {f1_score(true_labels, pred_labels):.4f}\")\n",
    "        \n",
    "    # print(f\"Epoch {epoch + 1}/{epochs}, Reconstruction Loss: {train_loss / len(train_dataloader):.4f}, Test Loss: {test_loss / len(test_dataloader):.4f}\")\n",
    "    \n",
    "# Summary\n",
    "print(\"Training complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0300, 0.0900, 0.0400])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Simuler des données (batch_size=3, num_features=4)\n",
    "inputs = torch.tensor([[1.0, 2.0, 3.0, 4.0],\n",
    "                       [2.0, 3.0, 4.0, 5.0],\n",
    "                       [1.5, 2.5, 3.5, 4.5]])\n",
    "\n",
    "outputs = torch.tensor([[1.1, 2.1, 2.9, 4.0],\n",
    "                        [2.0, 3.2, 4.2, 4.9],\n",
    "                        [1.4, 2.6, 3.6, 4.4]])\n",
    "\n",
    "# Calcul de la perte\n",
    "reconstruction_loss = nn.MSELoss(reduction='none')(outputs, inputs).sum(dim=1)\n",
    "print(reconstruction_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 1],\n",
       "       [1, 4]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "confusion_matrix(true_labels, pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cardfraud",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
